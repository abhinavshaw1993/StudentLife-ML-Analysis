{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "def change_labels(x):\n",
    "    label_dict = {\n",
    "         0.0:2\n",
    "        ,1.0:1\n",
    "        ,2.0:0\n",
    "        ,3.0:3\n",
    "        ,4.0:4\n",
    "       }\n",
    "    \n",
    "    return label_dict[x]\n",
    "\n",
    "data = pd.read_csv(\"data/variable_interval_aggregate_train.csv\", skip_blank_lines=False, index_col=0, infer_datetime_format=True)\n",
    "data.loc[:,\"stress_level\"] = data.loc[:,\"stress_level\"].apply(change_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified and shuffled train split.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "train_X , test_X, train_y, test_y = train_test_split(X, y, shuffle=False, stratify=None, test_size=0.25, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the values.\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "X = StandardScaler().fit_transform(X)\n",
    "X = normalize(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1e-06, 'max_iter': 60, 'penalty': 'l2'} 0.383147853736 LogisticRegression(C=1e-06, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=60, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\n",
      "\n",
      "\n",
      "Accuracy is 43.5714285714 %\n",
      "\n",
      "\n",
      "\n",
      "predicted values  [2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 3 2 2 2 2 2 3 2 2\n",
      " 2 3 2 2 3 2 2 2 2 2 3 2 2 2 2 2 2 4 2 2 3 2 2 2 2 2 3 2 2 2 3 3 2 3 2 3 3\n",
      " 2 3 3 2 2 2 2 2 2 3 2 2 2 2 3 2 2 3 2 2 2 2 2 2 2 2 3 2 0 2 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 4 2 2 2 2 2 2 3 3 2 3 3 3 2 2 2 3 2 3 3 2 3 3 3 2 3 2 2 3 3 2 2\n",
      " 3 2 3 1 2 1 3 2 3 1 3 2 2 3 2 3 2 2 3 2 4 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 3 2 1 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 2 2 2 2 2 1 2 2 0 0 2 2 2 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 1 2 2 1 2 2 2 2 2 2 2 2 2 2 1 2\n",
      " 2 2 2 2 2 2 2 2 2 2 3 3 3]\n",
      "\n",
      "\n",
      "\n",
      "f_1 score  [ 0.          0.05970149  0.58778626  0.28888889  0.05714286]\n",
      "Recall  [ 0.          0.03571429  0.82795699  0.21311475  0.03571429]\n",
      "precission  [ 0.          0.18181818  0.4556213   0.44827586  0.14285714]\n",
      "\n",
      "\n",
      "\n",
      "confusion_matrics  [[  0   3  22   3   0]\n",
      " [  1   2  47   6   0]\n",
      " [  4   3 154  21   4]\n",
      " [  1   3  90  26   2]\n",
      " [  0   0  25   2   1]]\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression on personalized aggregates.\n",
    "\n",
    "param_grid = [\n",
    "    {'penalty': [ \"l2\"],\n",
    "    'C' : [1e-5, 1e-6, 1e-7],\n",
    "    'max_iter' : [60 ,70 ,80 ,100, 120]}\n",
    " ]\n",
    "\n",
    "clf = GridSearchCV(LogisticRegression(), param_grid, cv=5, scoring=\"accuracy\")\n",
    "clf.fit(train_X, train_y)\n",
    "\n",
    "print(clf.best_params_, clf.best_score_, clf.best_estimator_)\n",
    "\n",
    "best_clf = clf.estimator\n",
    "best_clf.fit(train_X, train_y)\n",
    "pred_y = best_clf.predict(test_X)\n",
    "score = accuracy_score(test_y, pred_y, normalize=True)\n",
    "\n",
    "f1 = f1_score(test_y, pred_y, average=None)\n",
    "precission = precision_score(test_y, pred_y, average=None)\n",
    "recall = recall_score(test_y, pred_y, average=None)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(\"Accuracy is \"+ str(score * 100) + \" %\")\n",
    "print(\"\\n\\n\")\n",
    "print(\"predicted values \", pred_y)\n",
    "print(\"\\n\\n\")\n",
    "print(\"f_1 score \", f1)\n",
    "print(\"Recall \", recall)\n",
    "print(\"precission \", precission)\n",
    "print(\"\\n\\n\")\n",
    "print(\"confusion_matrics \\n\", confusion_matrix(test_y, pred_y, labels=[0,1,2,3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1e-07, 'max_iter': 60, 'penalty': 'l1'} 0.39586645469 LogisticRegression(C=1e-07, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=60, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\n",
      "\n",
      "\n",
      "Accuracy is 42.380952381 %\n",
      "\n",
      "\n",
      "\n",
      "predicted values [2 2 2 2 2 2 2 2 2 1 2 4 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 0 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 3 2 2 2 2 2 3 2 2\n",
      " 2 3 2 3 3 2 2 2 2 2 3 2 2 2 3 3 2 1 2 2 3 2 2 2 2 2 3 2 2 3 3 3 3 3 1 3 3\n",
      " 2 3 3 2 2 2 2 2 2 3 2 2 2 2 3 2 2 3 2 2 2 2 2 2 2 2 3 2 0 2 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 2 3 2 1 2 3 2 3 3 2 3 3 3 2 2 2 3 2 3 3 2 3 3 3 2 3 2 2 3 3 3 3\n",
      " 3 3 3 3 3 4 1 1 4 1 3 2 2 3 3 3 2 3 3 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 4 2 2 2 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 2 2 2 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 1 2 2 2 2 2 2 2 2 2 2 1 2\n",
      " 2 2 2 2 2 2 2 2 2 2 3 3 3]\n",
      "\n",
      "\n",
      "\n",
      "f_1 score  [ 0.          0.08823529  0.57699805  0.27979275  0.        ]\n",
      "Recall  [ 0.          0.05357143  0.79569892  0.22131148  0.        ]\n",
      "precission  [ 0.          0.25        0.45259939  0.38028169  0.        ]\n",
      "confusion_matrics \n",
      " [[  0   3  22   3   0]\n",
      " [  0   3  45   8   0]\n",
      " [  5   3 148  30   0]\n",
      " [  0   3  87  27   5]\n",
      " [  0   0  25   3   0]]\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression on generalized aggregates.\n",
    "\n",
    "param_grid = [\n",
    "    {'penalty': [ \"l1\", \"l2\"],\n",
    "    'C' : [ 1e-4, 1e-5, 1e-6, 1e-7, 1e-8],\n",
    "    'max_iter' : [60 ,70 ,80 ,100, 120]}\n",
    " ]\n",
    "\n",
    "clf = GridSearchCV(LogisticRegression(), param_grid, cv=5, scoring=\"accuracy\")\n",
    "\n",
    "# SLicing removes student_id as a feature in the table and makes the model generalized.\n",
    "clf.fit(train_X.iloc[:,1:], train_y)\n",
    "\n",
    "print(clf.best_params_, clf.best_score_, clf.best_estimator_)\n",
    "\n",
    "best_clf = clf.estimator\n",
    "best_clf.fit(train_X.iloc[:,1:], train_y)\n",
    "pred_y = best_clf.predict(test_X.iloc[:,1:])\n",
    "score = accuracy_score(test_y, pred_y, normalize=True)\n",
    "\n",
    "f1 = f1_score(test_y, pred_y, average=None)\n",
    "precission = precision_score(test_y, pred_y, average=None)\n",
    "recall = recall_score(test_y, pred_y, average=None)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(\"Accuracy is \"+ str(score * 100) + \" %\")\n",
    "print(\"\\n\\n\")\n",
    "print(\"predicted values\", pred_y)\n",
    "print(\"\\n\\n\")\n",
    "print(\"f_1 score \", f1)\n",
    "print(\"Recall \", recall)\n",
    "print(\"precission \", precission)\n",
    "print(\"confusion_matrics \\n\", confusion_matrix(test_y, pred_y, labels=[0,1,2,3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3.16394538e-04  -1.40447725e-03  -4.31310374e-06   2.49270399e-04\n",
      "    6.59901824e-05  -3.53121744e-04  -1.05003189e-04   5.72802324e-04\n",
      "   -2.25614736e-03  -2.97095152e-04   4.31618903e-04  -5.86473556e-06\n",
      "    3.63736795e-04   7.59400096e-06  -3.86886516e-05  -3.86886516e-05\n",
      "   -3.86886516e-05  -3.86886516e-05   7.70480859e-03  -1.69615469e-04\n",
      "    7.70480859e-03   1.33889135e-02  -5.45551795e-04  -1.04444670e-02\n",
      "   -3.54867249e-03   6.76581487e-04  -2.55691190e-06  -2.61140595e-03\n",
      "    5.64197602e-04  -4.94050031e-04  -6.70240097e-04   7.42850808e-04\n",
      "    9.11837836e-05   6.21419152e-06   4.79165411e-04  -7.83650791e-04\n",
      "   -8.75285610e-04  -3.60220829e-04  -1.71513025e-03  -6.23445905e-05\n",
      "   -1.73115414e-03   6.68024693e-04  -1.92822245e-03   7.83891971e-03\n",
      "   -5.14381719e-04  -1.83083836e-06   1.24011501e-03  -7.80940627e-04\n",
      "    3.71543341e-03  -1.01735813e-03   3.29509126e-03  -1.03899064e-03\n",
      "    3.13209197e-03  -1.05512059e-03   3.11254745e-03   1.18497658e-02\n",
      "    7.23629106e-03   9.93941128e-07   1.73460453e-04  -2.24824754e-03\n",
      "   -2.26987185e-03   2.79963252e-03   5.60584694e-04   7.33878820e-04\n",
      "   -3.32851894e-06   6.56705786e-04   4.47090969e-03   2.93638456e-04\n",
      "   -1.54879597e-03  -2.52730564e-03  -2.70166446e-05  -8.86725625e-07\n",
      "    6.86680026e-04  -6.40505065e-03   1.50567433e-04  -6.05926262e-03\n",
      "    5.66015774e-04  -6.00575051e-03   3.54621436e-04  -5.80050207e-03\n",
      "    3.21182747e-04  -2.23252910e-02  -1.25828453e-03   9.84456669e-07\n",
      "   -1.46644738e-03  -3.86886516e-05  -3.86886516e-05  -3.86886516e-05\n",
      "   -3.86886516e-05  -6.91346298e-04   1.63402359e-04  -6.91346298e-04]\n",
      " [ -1.76396598e-05  -1.56348340e-04  -2.64290173e-05  -2.13035012e-05\n",
      "   -1.26737192e-04   1.60256561e-03   2.74377825e-05  -1.57806633e-05\n",
      "   -1.26351760e-04  -3.64788378e-05  -3.71961766e-05   2.26313855e-05\n",
      "   -1.62792337e-03   1.37262953e-05  -4.05946498e-05  -4.05946498e-05\n",
      "   -4.05946498e-05  -4.05946498e-05  -3.75196258e-04  -9.55138063e-05\n",
      "   -3.75196258e-04  -4.04486918e-04  -1.38590989e-05  -8.11270317e-05\n",
      "   -1.35842573e-04  -2.11636011e-03   5.08430265e-06  -4.27138059e-04\n",
      "   -1.06493791e-03  -1.00679681e-03   9.96341726e-05   1.59391975e-03\n",
      "    9.09493791e-05  -2.07772028e-06  -1.20135949e-04  -8.24952031e-05\n",
      "   -1.42952104e-04  -8.25698307e-05  -1.43479155e-04  -1.10220831e-04\n",
      "   -1.19461513e-04  -1.36038426e-04  -7.61539171e-05  -9.11023453e-05\n",
      "    8.16732812e-06   1.26988667e-06  -2.93553944e-06  -1.72987754e-03\n",
      "    2.97748142e-03  -1.75649865e-03   2.93631972e-03  -1.75030854e-03\n",
      "    2.96880371e-03  -1.75340559e-03   2.97033829e-03   5.94746685e-04\n",
      "    3.61614911e-04   2.24147480e-05   2.61121938e-05  -6.12756117e-04\n",
      "   -2.02742933e-03  -1.37703625e-04   1.86424346e-03   1.94153724e-04\n",
      "    2.40561841e-06  -7.10471362e-05  -3.26162048e-04   2.56616573e-04\n",
      "   -2.21490163e-04   5.86846940e-04  -2.45319356e-04   5.69518575e-06\n",
      "   -1.45241794e-04  -3.12916547e-04  -3.92773207e-08  -4.04567879e-04\n",
      "   -2.36460064e-05  -3.59506396e-04  -5.28546445e-06  -3.59252883e-04\n",
      "    3.75517880e-06  -9.09536882e-04  -1.87767786e-05  -1.09927786e-06\n",
      "   -9.95378653e-05  -4.05946498e-05  -4.05946498e-05  -4.05946498e-05\n",
      "   -4.05946498e-05  -1.60565806e-04   8.45161872e-05  -1.60565806e-04]\n",
      " [ -3.32882291e-04   3.66298086e-03   1.03291362e-04  -2.73678572e-04\n",
      "    4.41694933e-05  -2.03082206e-04   8.27180302e-06  -5.02704843e-04\n",
      "    2.36625424e-03   1.04768240e-03   6.85028496e-04  -1.43095100e-05\n",
      "    2.07260136e-04  -2.13962757e-05  -5.23631297e-05  -5.23631297e-05\n",
      "   -5.23631297e-05  -5.23631297e-05  -7.86034428e-04   1.64973498e-04\n",
      "   -7.86034428e-04  -1.18561355e-02  -8.09748732e-04   2.84200748e-03\n",
      "    4.39463679e-03   7.04011901e-04   4.40338667e-06   8.95431759e-03\n",
      "    2.43696835e-04   6.97565232e-04  -2.71274772e-03   7.02346445e-04\n",
      "    1.24966399e-04   2.98539282e-06   1.05802260e-05  -6.01796866e-04\n",
      "    9.76401824e-04   3.69501613e-03   6.33107362e-03   9.95776278e-04\n",
      "    3.53396247e-03  -8.67533240e-05   2.16768915e-03  -1.99755403e-03\n",
      "    9.33231658e-03  -9.22614399e-08   1.63925976e-03  -2.88513874e-03\n",
      "    1.35075031e-03  -1.76111209e-03   1.60450875e-03  -2.04008826e-03\n",
      "    2.38929020e-04  -1.91659777e-03  -3.71491730e-04  -2.36046064e-04\n",
      "   -1.75759186e-04  -4.94922450e-06   4.74054245e-04  -9.28220879e-04\n",
      "    1.29526617e-03   3.22880122e-03  -3.08276847e-03  -3.12255776e-04\n",
      "   -1.14331592e-06  -3.93808513e-04  -2.03426963e-03  -1.23187223e-03\n",
      "    2.05763767e-03   1.28042295e-03   1.25551519e-04  -4.16399063e-06\n",
      "   -4.33976480e-03  -1.65289619e-04   1.10394323e-03  -1.85174075e-03\n",
      "    1.07647402e-03  -1.25937976e-03   1.04644957e-03  -1.63475087e-03\n",
      "    9.24743676e-04   2.73565016e-02   5.90520908e-03  -4.70888374e-07\n",
      "    3.18950819e-03  -5.23631297e-05  -5.23631297e-05  -5.23631297e-05\n",
      "   -5.23631297e-05   4.62402411e-05  -1.64776506e-04   4.62402411e-05]\n",
      " [  8.66804296e-06  -3.57429876e-05   7.39507955e-06   1.39705830e-05\n",
      "   -5.34285749e-05  -8.54719666e-04   2.15134938e-04  -7.31287416e-06\n",
      "    8.67905856e-06  -3.71850620e-05  -5.27928621e-05  -5.16667441e-06\n",
      "    8.46097003e-04  -2.92883236e-05  -5.68166340e-05  -5.68166340e-05\n",
      "   -5.68166340e-05  -5.68166340e-05  -8.57295285e-05   7.39905152e-05\n",
      "   -8.57295285e-05   1.46246304e-04  -4.84163014e-05   7.66162109e-05\n",
      "   -2.54056530e-04   2.81691163e-03  -9.19777427e-06  -1.23442129e-03\n",
      "    1.14666063e-03   1.50053904e-03   1.09315049e-04  -1.44349077e-03\n",
      "   -1.84136358e-04  -3.85362624e-06  -6.07121903e-05  -3.22972453e-04\n",
      "   -9.76797760e-05  -4.45589585e-04  -1.94563164e-04  -3.64143003e-04\n",
      "   -1.40142896e-04  -3.43986919e-04  -1.18610476e-04  -5.82457475e-04\n",
      "   -3.75876231e-04  -4.39164156e-07  -1.42400441e-04  -2.53663556e-03\n",
      "    4.09748160e-03  -2.50578638e-03   4.14002521e-03  -2.51370538e-03\n",
      "    4.15700939e-03  -2.50788349e-03   4.17334513e-03  -2.70928862e-03\n",
      "   -1.56251869e-03   3.01258273e-06  -3.54410456e-05   1.49472030e-03\n",
      "    4.73617494e-04   1.93076680e-04  -6.44415701e-04  -7.63970073e-04\n",
      "    3.03940330e-06  -1.74837117e-04  -1.44968417e-03   6.99454908e-04\n",
      "   -1.02079381e-04  -1.87846435e-05  -1.16347307e-04   4.50107369e-06\n",
      "   -4.42635923e-05  -9.79610538e-05  -2.08162082e-04  -7.15558138e-05\n",
      "   -2.12986848e-04  -7.92863899e-05  -2.11338112e-04  -6.96229336e-05\n",
      "   -2.12156757e-04  -7.12214649e-05  -3.71151922e-04  -1.68644746e-06\n",
      "   -9.04631334e-05  -5.68166340e-05  -5.68166340e-05  -5.68166340e-05\n",
      "   -5.68166340e-05  -2.04993577e-03  -6.86703853e-05  -2.04993577e-03]\n",
      " [ -3.31193367e-05  -1.01311423e-03  -4.39473152e-05  -4.19759359e-05\n",
      "    8.69564026e-05  -1.34083307e-03  -9.46475934e-05  -1.72369656e-04\n",
      "   -3.56968240e-04  -3.51798497e-04  -1.84598933e-04   4.18131076e-05\n",
      "    1.34414663e-03   5.29415439e-05  -1.51892266e-04  -1.51892266e-04\n",
      "   -1.51892266e-04  -1.51892266e-04  -5.94779529e-03  -4.75115201e-04\n",
      "   -5.94779529e-03   3.13179000e-03   4.34178468e-03   2.05699106e-03\n",
      "    3.30982660e-03  -5.31780403e-03  -3.23358073e-06  -1.77297500e-03\n",
      "    2.11499275e-03  -9.44010745e-04   4.06191129e-03  -4.34331772e-03\n",
      "   -1.30239914e-04  -1.33675200e-05  -5.63887756e-04   1.08978093e-05\n",
      "   -8.84689207e-05  -1.06676711e-03  -1.12474418e-03  -6.87918711e-04\n",
      "   -6.24228032e-04  -7.14611030e-04  -6.33863200e-04  -7.99816015e-03\n",
      "   -5.08843926e-03  -4.33369932e-06  -1.86336630e-03  -6.95450552e-03\n",
      "    1.11578212e-02  -7.17808014e-03   1.09476513e-02  -7.16020445e-03\n",
      "    1.10680405e-02  -7.19551861e-03   1.10699390e-02   6.33812238e-03\n",
      "    3.73469983e-03   6.88870034e-06   2.55437228e-05  -1.07607739e-03\n",
      "   -9.76669713e-05  -7.65437946e-04   2.44604582e-03  -5.17608526e-05\n",
      "   -6.36943155e-06   2.52125045e-04   7.76634047e-04  -8.15947283e-05\n",
      "    2.55640303e-03  -1.52547138e-03   1.29835939e-04  -2.47973386e-06\n",
      "    6.09975655e-04  -1.99702154e-03  -5.80276711e-04  -1.00573515e-03\n",
      "   -4.52542780e-04  -1.56742046e-03  -5.49337173e-04  -1.64995663e-03\n",
      "   -5.41751644e-04  -3.95034053e-03  -7.19521638e-04   6.04088212e-06\n",
      "   -2.69736867e-04  -1.51892266e-04  -1.51892266e-04  -1.51892266e-04\n",
      "   -1.51892266e-04   2.70284253e-03   4.75970587e-04   2.70284253e-03]]\n"
     ]
    }
   ],
   "source": [
    "print (best_clf.coef_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    508\n",
      "3    272\n",
      "1    221\n",
      "0    210\n",
      "4     47\n",
      "Name: stress_level, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
