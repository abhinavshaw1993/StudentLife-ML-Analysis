{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "def change_labels(x):\n",
    "    label_dict = {\n",
    "         0.0:2\n",
    "        ,1.0:1\n",
    "        ,2.0:0\n",
    "        ,3.0:3\n",
    "        ,4.0:4\n",
    "       }\n",
    "    \n",
    "    return label_dict[x]\n",
    "\n",
    "data = pd.read_csv(\"data/variable_interval_aggregate_train.csv\", skip_blank_lines=False, index_col=0, infer_datetime_format=True)\n",
    "data.loc[:,\"stress_level\"] = data.loc[:,\"stress_level\"].apply(change_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified and shuffled train split.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "train_X , test_X, train_y, test_y = train_test_split(X, y, shuffle=False, stratify=None, test_size=0.25, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the values.\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "X = StandardScaler().fit_transform(X)\n",
    "X = normalize(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1e-06, 'max_iter': 60, 'penalty': 'l2'} 0.383147853736 LogisticRegression(C=1e-06, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=60, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\n",
      "\n",
      "\n",
      "Accuracy is 43.5714285714 %\n",
      "\n",
      "\n",
      "\n",
      "predicted values  [2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 3 2 2 2 2 2 3 2 2\n",
      " 2 3 2 2 3 2 2 2 2 2 3 2 2 2 2 2 2 4 2 2 3 2 2 2 2 2 3 2 2 2 3 3 2 3 2 3 3\n",
      " 2 3 3 2 2 2 2 2 2 3 2 2 2 2 3 2 2 3 2 2 2 2 2 2 2 2 3 2 0 2 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 4 2 2 2 2 2 2 3 3 2 3 3 3 2 2 2 3 2 3 3 2 3 3 3 2 3 2 2 3 3 2 2\n",
      " 3 2 3 1 2 1 3 2 3 1 3 2 2 3 2 3 2 2 3 2 4 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 3 2 1 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 2 2 2 2 2 1 2 2 0 0 2 2 2 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 1 2 2 1 2 2 2 2 2 2 2 2 2 2 1 2\n",
      " 2 2 2 2 2 2 2 2 2 2 3 3 3]\n",
      "\n",
      "\n",
      "\n",
      "f_1 score  [ 0.          0.05970149  0.58778626  0.28888889  0.05714286]\n",
      "Recall  [ 0.          0.03571429  0.82795699  0.21311475  0.03571429]\n",
      "precission  [ 0.          0.18181818  0.4556213   0.44827586  0.14285714]\n",
      "\n",
      "\n",
      "\n",
      "confusion_matrics  [[  0   3  22   3   0]\n",
      " [  1   2  47   6   0]\n",
      " [  4   3 154  21   4]\n",
      " [  1   3  90  26   2]\n",
      " [  0   0  25   2   1]]\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression on personalized aggregates.\n",
    "\n",
    "param_grid = [\n",
    "    {'penalty': [ \"l2\"],\n",
    "    'C' : [1e-5, 1e-6, 1e-7],\n",
    "    'max_iter' : [60 ,70 ,80 ,100, 120]}\n",
    " ]\n",
    "\n",
    "clf = GridSearchCV(LogisticRegression(), param_grid, cv=5, scoring=\"accuracy\")\n",
    "clf.fit(train_X, train_y)\n",
    "\n",
    "print(clf.best_params_, clf.best_score_, clf.best_estimator_)\n",
    "\n",
    "best_clf = clf.estimator\n",
    "best_clf.fit(train_X, train_y)\n",
    "pred_y = best_clf.predict(test_X)\n",
    "score = accuracy_score(test_y, pred_y, normalize=True)\n",
    "\n",
    "f1 = f1_score(test_y, pred_y, average=None)\n",
    "precission = precision_score(test_y, pred_y, average=None)\n",
    "recall = recall_score(test_y, pred_y, average=None)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(\"Accuracy is \"+ str(score * 100) + \" %\")\n",
    "print(\"\\n\\n\")\n",
    "print(\"predicted values \", pred_y)\n",
    "print(\"\\n\\n\")\n",
    "print(\"f_1 score \", f1)\n",
    "print(\"Recall \", recall)\n",
    "print(\"precission \", precission)\n",
    "print(\"\\n\\n\")\n",
    "print(\"confusion_matrics \\n\", confusion_matrix(test_y, pred_y, labels=[0,1,2,3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1e-07, 'max_iter': 60, 'penalty': 'l1'} 0.39586645469 LogisticRegression(C=1e-07, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=60, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\n",
      "\n",
      "\n",
      "Accuracy is 42.380952381 %\n",
      "\n",
      "\n",
      "\n",
      "predicted values [2 2 2 2 2 2 2 2 2 1 2 4 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 0 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 3 2 2 2 2 2 3 2 2\n",
      " 2 3 2 3 3 2 2 2 2 2 3 2 2 2 3 3 2 1 2 2 3 2 2 2 2 2 3 2 2 3 3 3 3 3 1 3 3\n",
      " 2 3 3 2 2 2 2 2 2 3 2 2 2 2 3 2 2 3 2 2 2 2 2 2 2 2 3 2 0 2 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 2 3 2 1 2 3 2 3 3 2 3 3 3 2 2 2 3 2 3 3 2 3 3 3 2 3 2 2 3 3 3 3\n",
      " 3 3 3 3 3 4 1 1 4 1 3 2 2 3 3 3 2 3 3 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 4 2 2 2 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 2 2 2 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 1 2 2 2 2 2 2 2 2 2 2 1 2\n",
      " 2 2 2 2 2 2 2 2 2 2 3 3 3]\n",
      "\n",
      "\n",
      "\n",
      "f_1 score  [ 0.          0.08823529  0.57699805  0.27979275  0.        ]\n",
      "Recall  [ 0.          0.05357143  0.79569892  0.22131148  0.        ]\n",
      "precission  [ 0.          0.25        0.45259939  0.38028169  0.        ]\n",
      "confusion_matrics \n",
      " [[  0   3  22   3   0]\n",
      " [  0   3  45   8   0]\n",
      " [  5   3 148  30   0]\n",
      " [  0   3  87  27   5]\n",
      " [  0   0  25   3   0]]\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression on generalized aggregates.\n",
    "\n",
    "param_grid = [\n",
    "    {'penalty': [ \"l1\", \"l2\"],\n",
    "    'C' : [ 1e-4, 1e-5, 1e-6, 1e-7, 1e-8],\n",
    "    'max_iter' : [60 ,70 ,80 ,100, 120]}\n",
    " ]\n",
    "\n",
    "clf = GridSearchCV(LogisticRegression(), param_grid, cv=5, scoring=\"accuracy\")\n",
    "\n",
    "# SLicing removes student_id as a feature in the table and makes the model generalized.\n",
    "clf.fit(train_X.iloc[:,1:], train_y)\n",
    "\n",
    "print(clf.best_params_, clf.best_score_, clf.best_estimator_)\n",
    "\n",
    "best_clf = clf.estimator\n",
    "best_clf.fit(train_X.iloc[:,1:], train_y)\n",
    "pred_y = best_clf.predict(test_X.iloc[:,1:])\n",
    "score = accuracy_score(test_y, pred_y, normalize=True)\n",
    "\n",
    "f1 = f1_score(test_y, pred_y, average=None)\n",
    "precission = precision_score(test_y, pred_y, average=None)\n",
    "recall = recall_score(test_y, pred_y, average=None)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(\"Accuracy is \"+ str(score * 100) + \" %\")\n",
    "print(\"\\n\\n\")\n",
    "print(\"predicted values\", pred_y)\n",
    "print(\"\\n\\n\")\n",
    "print(\"f_1 score \", f1)\n",
    "print(\"Recall \", recall)\n",
    "print(\"precission \", precission)\n",
    "print(\"confusion_matrics \\n\", confusion_matrix(test_y, pred_y, labels=[0,1,2,3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['student_id' 'activity_details_activity_inference_min'\n",
      " 'activity_details_activity_inference_max'\n",
      " 'activity_details_activity_inference_mean'\n",
      " 'activity_details_activity_inference_median'\n",
      " 'activity_details_activity_inference_sum' 'activity_details_time_delta'\n",
      " 'activity_details_count' 'audio_details_audio_activity_inference_min'\n",
      " 'audio_details_audio_activity_inference_max'\n",
      " 'audio_details_audio_activity_inference_mean'\n",
      " 'audio_details_audio_activity_inference_median'\n",
      " 'audio_details_audio_activity_inference_sum' 'audio_details_time_delta'\n",
      " 'audio_details_count' 'call_log_details_call_recorded_min'\n",
      " 'call_log_details_call_recorded_max' 'call_log_details_call_recorded_mean'\n",
      " 'call_log_details_call_recorded_median'\n",
      " 'call_log_details_call_recorded_sum' 'call_log_details_time_delta'\n",
      " 'call_log_details_count' 'conversation_details_conv_duration_min_min'\n",
      " 'conversation_details_conv_duration_min_max'\n",
      " 'conversation_details_conv_duration_min_mean'\n",
      " 'conversation_details_conv_duration_min_median'\n",
      " 'conversation_details_conv_duration_min_sum'\n",
      " 'conversation_details_time_delta' 'conversation_details_count'\n",
      " 'dark_details_dark_duration_min_min' 'dark_details_dark_duration_min_max'\n",
      " 'dark_details_dark_duration_min_mean'\n",
      " 'dark_details_dark_duration_min_median'\n",
      " 'dark_details_dark_duration_min_sum' 'dark_details_time_delta'\n",
      " 'dark_details_count' 'dinning_details_venue_id_min'\n",
      " 'dinning_details_meal_type_id_min' 'dinning_details_venue_id_max'\n",
      " 'dinning_details_meal_type_id_max' 'dinning_details_venue_id_mean'\n",
      " 'dinning_details_meal_type_id_mean' 'dinning_details_venue_id_median'\n",
      " 'dinning_details_meal_type_id_median' 'dinning_details_venue_id_sum'\n",
      " 'dinning_details_meal_type_id_sum' 'dinning_details_time_delta'\n",
      " 'dinning_details_count' 'gps_details_latitude_min'\n",
      " 'gps_details_longitude_min' 'gps_details_latitude_max'\n",
      " 'gps_details_longitude_max' 'gps_details_latitude_mean'\n",
      " 'gps_details_longitude_mean' 'gps_details_latitude_median'\n",
      " 'gps_details_longitude_median' 'gps_details_latitude_sum'\n",
      " 'gps_details_longitude_sum' 'gps_details_time_delta' 'gps_details_count'\n",
      " 'phonecharge_details_phonecharge_duration_min_min'\n",
      " 'phonecharge_details_phonecharge_duration_min_max'\n",
      " 'phonecharge_details_phonecharge_duration_min_mean'\n",
      " 'phonecharge_details_phonecharge_duration_min_median'\n",
      " 'phonecharge_details_phonecharge_duration_min_sum'\n",
      " 'phonecharge_details_time_delta' 'phonecharge_details_count'\n",
      " 'phonelock_details_phonelock_duration_min_min'\n",
      " 'phonelock_details_phonelock_duration_min_max'\n",
      " 'phonelock_details_phonelock_duration_min_mean'\n",
      " 'phonelock_details_phonelock_duration_min_median'\n",
      " 'phonelock_details_phonelock_duration_min_sum'\n",
      " 'phonelock_details_time_delta' 'phonelock_details_count'\n",
      " 'sleep_details_hours_slept_min' 'sleep_details_sleep_rating_min'\n",
      " 'sleep_details_hours_slept_max' 'sleep_details_sleep_rating_max'\n",
      " 'sleep_details_hours_slept_mean' 'sleep_details_sleep_rating_mean'\n",
      " 'sleep_details_hours_slept_median' 'sleep_details_sleep_rating_median'\n",
      " 'sleep_details_hours_slept_sum' 'sleep_details_sleep_rating_sum'\n",
      " 'sleep_details_time_delta' 'sleep_details_count'\n",
      " 'sms_details_sms_instance_min' 'sms_details_sms_instance_max'\n",
      " 'sms_details_sms_instance_mean' 'sms_details_sms_instance_median'\n",
      " 'sms_details_sms_instance_sum' 'sms_details_time_delta'\n",
      " 'sms_details_count']\n"
     ]
    }
   ],
   "source": [
    "print(train_X.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
